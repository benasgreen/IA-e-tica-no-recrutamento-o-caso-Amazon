# IA-e-tica-no-recrutamento-o-caso-Amazon


âš–ï¸ IA e Ã©tica no recrutamento: o caso Amazon

Em 2018, a Amazon suspendeu um sistema de IA para seleÃ§Ã£o de currÃ­culos apÃ³s descobrir que o algoritmo discriminava candidatas mulheres. O modelo foi treinado com dados histÃ³ricos (predominantemente masculinos), reproduzindo e ampliando vieses.

ğŸ” Nossa anÃ¡lise destacou:
â€¢ ViÃ©s de dados â†’ histÃ³rico enviesado reforÃ§ou desigualdade de gÃªnero.
â€¢ TransparÃªncia limitada â†’ sistema funcionava como uma â€œblack boxâ€, sem explicabilidade.
â€¢ Impactos sociais â†’ exclusÃ£o de mulheres e risco de violaÃ§Ã£o do direito Ã  igualdade.
â€¢ GovernanÃ§a falha â†’ ausÃªncia de mÃ©tricas de fairness e auditorias preventivas.

âœ… Posicionamento: acreditamos que sistemas de IA em recrutamento sÃ³ devem ser aplicados com prÃ¡ticas de Ethical AI by Design, garantindo diversidade nos dados, explicabilidade e respeito Ã s legislaÃ§Ãµes (como a LGPD no Brasil).

ğŸ“„ Confira o relatÃ³rio completo com a anÃ¡lise detalhada e recomendaÃ§Ãµes: (https://github.com/benasgreen/IA-e-tica-no-recrutamento-o-caso-Amazon)

ğŸ‘‰ E vocÃª, acredita que a IA pode ser usada de forma justa em processos seletivos?

#Ã‰ticaEmIA #InteligÃªnciaArtificial #Recrutamento #ViÃ©sAlgorÃ­tmico #LGPD
