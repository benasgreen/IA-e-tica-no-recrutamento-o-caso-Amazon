# IA-e-tica-no-recrutamento-o-caso-Amazon


⚖️ IA e ética no recrutamento: o caso Amazon

Em 2018, a Amazon suspendeu um sistema de IA para seleção de currículos após descobrir que o algoritmo discriminava candidatas mulheres. O modelo foi treinado com dados históricos (predominantemente masculinos), reproduzindo e ampliando vieses.

🔍 Nossa análise destacou:
• Viés de dados → histórico enviesado reforçou desigualdade de gênero.
• Transparência limitada → sistema funcionava como uma “black box”, sem explicabilidade.
• Impactos sociais → exclusão de mulheres e risco de violação do direito à igualdade.
• Governança falha → ausência de métricas de fairness e auditorias preventivas.

✅ Posicionamento: acreditamos que sistemas de IA em recrutamento só devem ser aplicados com práticas de Ethical AI by Design, garantindo diversidade nos dados, explicabilidade e respeito às legislações (como a LGPD no Brasil).

📄 Confira o relatório completo com a análise detalhada e recomendações: (https://github.com/benasgreen/IA-e-tica-no-recrutamento-o-caso-Amazon)

👉 E você, acredita que a IA pode ser usada de forma justa em processos seletivos?

#ÉticaEmIA #InteligênciaArtificial #Recrutamento #ViésAlgorítmico #LGPD
